{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-06T10:11:07.496721Z",
     "start_time": "2024-01-06T10:11:07.496122Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score, KFold,learning_curve\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score,make_scorer\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from scipy import stats\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.colors import BoundaryNorm\n"
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load the data\n",
    "mb_raw_data = pd.read_csv('../../data/mann_bruker.txt', sep='\\t')\n",
    "\n",
    "# Keep only necessary columns\n",
    "mb_clean_frame = mb_raw_data[['Sequence', 'm/z', 'CCS','Mass','Charge','Length']]\n",
    "# Group by 'Sequence' and 'Charge', and calculate median of 'Mass' and 'CCS'\n",
    "mb_clean_frame = mb_clean_frame.groupby(['Sequence', 'Charge']).agg({'Mass':'median', 'CCS':'median','Length':'median'}).reset_index()\n",
    "# Perform z-score transformation\n",
    "mb_clean_frame['CCS_z'] = stats.zscore(mb_clean_frame['CCS'])\n",
    "\n",
    "# Save the mean and std for later use\n",
    "ccs_mean = mb_clean_frame['CCS'].mean()\n",
    "ccs_std = mb_clean_frame['CCS'].std()\n",
    "\n",
    "# Delete the raw data frame to save memory\n",
    "del mb_raw_data\n",
    "# randomize data set\n",
    "mb_clean_frame = mb_clean_frame.sample(frac=1, random_state=1)"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T10:11:11.651352Z",
     "start_time": "2024-01-06T10:11:08.728134Z"
    }
   },
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Split the data into input (m/z) and output (CCS) variables\n",
    "X = mb_clean_frame[['Mass', 'Charge', 'Length']]\n",
    "y = mb_clean_frame['CCS_z']\n",
    "# Define the number of folds\n",
    "k = 4\n",
    "# Number of trees\n",
    "n = 50"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T10:11:11.656897Z",
     "start_time": "2024-01-06T10:11:11.650359Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform k-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T10:11:25.077012Z",
     "start_time": "2024-01-06T10:11:12.013050Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1\n",
      "Fold: 2\n",
      "Fold: 3\n",
      "Fold: 4\n",
      "Average Mean Squared Error: 7.318639233783918e-73\n",
      "Average Median Relative Error: 0.016806985984330135\n",
      "Average R^2 Score: 0.9890778874242914\n",
      "Time elapsed: 62.35 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "kf = KFold(n_splits=k)\n",
    "mse_scores = []\n",
    "median_relative_errors = []\n",
    "r2_scores = []\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    model = RandomForestRegressor(n_estimators=n, random_state=1,n_jobs=-1)\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Convert predictions back to original scale\n",
    "    y_pred_orig = y_pred * ccs_std + ccs_mean\n",
    "    y_test_orig = y_test * ccs_std + ccs_mean\n",
    "\n",
    "\n",
    "    mse = mean_squared_error(y_test_orig, y_pred_orig)\n",
    "    mse_scores.append(mse)\n",
    "\n",
    "    relative_errors = np.abs((y_pred_orig - y_test_orig) / y_test_orig)\n",
    "    median_relative_error = np.median(relative_errors)\n",
    "    median_relative_errors.append(median_relative_error)\n",
    "\n",
    "    r2 = r2_score(y_test_orig, y_pred_orig)\n",
    "    r2_scores.append(r2)\n",
    "    # Progress update\n",
    "    print(\"Fold:\", len(mse_scores))\n",
    "\n",
    "# Create the final model\n",
    "final_model = RandomForestRegressor(n_estimators=n, random_state=1,n_jobs=-1)\n",
    "final_model.fit(X, y)\n",
    "\n",
    "print(\"Average Mean Squared Error:\", np.mean(mse_scores))\n",
    "print(\"Average Median Relative Error:\", np.mean(median_relative_errors))\n",
    "print(\"Average R^2 Score:\", np.mean(r2_scores))\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f'Time elapsed: {elapsed_time:.2f} seconds')"
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "\n",
    "def median_relative_error(y_true, y_pred):\n",
    "    return np.median(np.abs((y_pred - y_true) / y_true))\n",
    "\n",
    "scorer = make_scorer(median_relative_error, greater_is_better=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-19T16:15:33.147425Z",
     "start_time": "2023-12-19T16:15:33.130388200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|â–Œ         | 6/100 [00:11<04:01,  2.57s/it]"
     ]
    }
   ],
   "source": [
    "train_sizes = np.linspace(0.01, 1.0, 100)\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=n, random_state=1, n_jobs=4)\n",
    "\n",
    "def median_relative_error(y_true, y_pred):\n",
    "    y_pred_orig = y_pred * ccs_std + ccs_mean\n",
    "    y_true_orig = y_true * ccs_std + ccs_mean\n",
    "    return np.median(np.abs((y_pred_orig - y_true_orig) / y_true_orig))\n",
    "\n",
    "median_relative_error_scores = []\n",
    "R2_scores = []\n",
    "data_sizes = []\n",
    "\n",
    "for train_size in tqdm(train_sizes):\n",
    "    kf = KFold(n_splits=k)\n",
    "    data = mb_clean_frame.sample(frac=train_size, random_state=1)\n",
    "    X = data[['Mass', 'Charge', 'Length']]\n",
    "    y = data['CCS_z']\n",
    "    data_sizes.append(len(data))\n",
    "    median_relative_errors = []\n",
    "    r2_scores = []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        model = RandomForestRegressor(n_estimators=n, random_state=1,n_jobs=-1)\n",
    "    \n",
    "        model.fit(X_train, y_train)\n",
    "    \n",
    "        y_pred = model.predict(X_test)\n",
    "    \n",
    "        y_pred_orig = y_pred * ccs_std + ccs_mean\n",
    "        y_test_orig = y_test * ccs_std + ccs_mean\n",
    "    \n",
    "        \n",
    "        relative_errors = np.abs((y_pred_orig - y_test_orig) / y_test_orig)\n",
    "        median_relative_error = np.median(relative_errors)\n",
    "        median_relative_errors.append(median_relative_error)\n",
    "\n",
    "        r2 = r2_score(y_test_orig, y_pred_orig)\n",
    "        r2_scores.append(r2)\n",
    "    \n",
    "    median_relative_error_scores.append(np.mean(median_relative_errors))\n",
    "    R2_scores.append(np.mean(r2_scores))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-19T17:16:00.807431300Z",
     "start_time": "2023-12-19T16:44:34.670965800Z"
    },
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot Median Relative Error with trendline\n",
    "plt.figure(figsize=(8, 6), dpi=300)\n",
    "plt.scatter(data_sizes, median_relative_error_scores, marker='o')\n",
    "coeffs = np.polyfit(data_sizes, median_relative_error_scores, 2)  \n",
    "poly = np.poly1d(coeffs)\n",
    "plt.plot(sorted(data_sizes), poly(sorted(data_sizes)), color='red')  \n",
    "plt.title('Median Relative Error vs Data Size')\n",
    "plt.xlabel('Data Size')\n",
    "plt.ylabel('Median Relative Error')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot R^2 Scores with trendline\n",
    "plt.figure(figsize=(8, 6), dpi=300)\n",
    "plt.scatter(data_sizes, R2_scores, marker='o')\n",
    "coeffs = np.polyfit(data_sizes, R2_scores, 2)  \n",
    "poly = np.poly1d(coeffs)\n",
    "plt.plot(sorted(data_sizes), poly(sorted(data_sizes)), color='red')  \n",
    "plt.title('R^2 Score vs Data Size')\n",
    "plt.xlabel('Data Size')\n",
    "plt.ylabel('R^2 Score')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-19T17:22:11.340920500Z",
     "start_time": "2023-12-19T17:22:08.455141100Z"
    },
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Save the model to a file\n",
    "#filename = 'random_forest'\n",
    "#pickle.dump(model, open(filename, 'wb'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "mb_clean_frame['Predicted CCS'] = final_model.predict(X)\n",
    "\n",
    "# Reverse the z-score transformation\n",
    "mb_clean_frame['Predicted CCS'] = mb_clean_frame['Predicted CCS'] * ccs_std + ccs_mean\n"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T10:11:26.172182Z",
     "start_time": "2024-01-06T10:11:25.081014Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T10:12:38.021717Z",
     "start_time": "2024-01-06T10:12:33.795977Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "mb_clean_frame.plot.scatter(\n",
    "    x='CCS',\n",
    "    y='Predicted CCS',\n",
    "    c='Length',\n",
    "    cmap='winter',\n",
    "    alpha=0.2,\n",
    "    vmin=mb_clean_frame['Length'].min(),\n",
    "    vmax=mb_clean_frame['Length'].max()\n",
    ")\n",
    "mb_clean_frame.plot.hexbin(\n",
    "    x='CCS',\n",
    "    y='Predicted CCS',\n",
    "    C='Length',\n",
    "    reduce_C_function=np.mean,\n",
    "    gridsize=50,\n",
    "    cmap='magma'\n",
    ")\n",
    "\n",
    "# Print the Spearman's correlation coefficient between the predicted and actual CCS values\n",
    "print(\"Spearman's Correlation Coefficient:\", mb_clean_frame['CCS'].corr(mb_clean_frame['Predicted CCS'], method='spearman'))\n",
    "# Create a scatter plot between the percent error and length\n",
    "mb_clean_frame['Percent Error'] = np.abs((mb_clean_frame['Predicted CCS'] - mb_clean_frame['CCS']) / mb_clean_frame['CCS'])\n",
    "mb_clean_frame.plot.scatter(\n",
    "    x='Length',\n",
    "    y='Percent Error',\n",
    "    alpha=0.2,\n",
    "    vmin=mb_clean_frame['Length'].min(),\n",
    "    vmax=mb_clean_frame['Length'].max()\n",
    ")\n",
    "\n",
    "\n",
    "boundaries = [0.5, 1.5, 2.5, 3.5, 4.5]\n",
    "cmap = mcolors.ListedColormap(['orange', 'blue', 'green', 'red'])\n",
    "\n",
    "norm = BoundaryNorm(boundaries, cmap.N, clip=True)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "scatter = ax.scatter(\n",
    "    x=mb_clean_frame['CCS'],\n",
    "    y=mb_clean_frame['Predicted CCS'],\n",
    "    c=mb_clean_frame['Charge'],\n",
    "    cmap=cmap,\n",
    "    norm=norm,\n",
    "    alpha=0.2\n",
    ")\n",
    "ax.set_xlabel('Experimental CCS')\n",
    "ax.set_ylabel('Predicted CCS')\n",
    "\n",
    "cbar = plt.colorbar(scatter, ticks=[1, 2, 3, 4])\n",
    "cbar.set_label('Charge')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "ccs_data = mb_clean_frame[\"CCS\"].to_numpy()\n",
    "predicted_ccs_data = mb_clean_frame[\"Predicted CCS\"].to_numpy()\n",
    "\n",
    "\n",
    "x = mb_clean_frame[\"CCS\"]\n",
    "y = mb_clean_frame[\"Predicted CCS\"]\n",
    "\n",
    "plt.hist2d(x, y, bins=[30,30],norm=mcolors.LogNorm())\n",
    "plt.xlabel(\"Experimental CCS\")\n",
    "plt.ylabel(\"Predicted CCS\")\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-05T19:19:43.872387Z",
     "start_time": "2024-01-05T19:19:43.426315Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get the importances from the final model\n",
    "importances = final_model.feature_importances_\n",
    "# Sort the feature importances in descending order\n",
    "indices = np.argsort(importances)[::-1]\n",
    "features = X.columns\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Feature Importance\")\n",
    "plt.bar(range(X.shape[1]), importances[indices], color=\"#3070B3\", align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), features[indices], rotation=0)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.ylabel('Feature Importance')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T11:36:23.925909900Z",
     "start_time": "2024-01-04T11:36:23.779849200Z"
    },
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
