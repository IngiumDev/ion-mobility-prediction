{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-09T09:20:57.582004Z",
     "start_time": "2023-10-09T09:20:56.590610Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score, KFold,learning_curve\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from scipy import stats"
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h8/62vn1gzj3456t6qsdpq7mx3w0000gn/T/ipykernel_10667/1776410603.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mb_clean_frame['CCS_z'] = stats.zscore(mb_clean_frame['CCS'])\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "mb_raw_data = pd.read_csv('../../data/mann_bruker.txt', sep='\\t')\n",
    "\n",
    "# Keep only necessary columns\n",
    "mb_clean_frame = mb_raw_data[['Sequence', 'm/z', 'CCS','Mass','Charge','Length']]\n",
    "\n",
    "# Perform z-score transformation\n",
    "mb_clean_frame['CCS_z'] = stats.zscore(mb_clean_frame['CCS'])\n",
    "\n",
    "# Save the mean and std for later use\n",
    "ccs_mean = mb_clean_frame['CCS'].mean()\n",
    "ccs_std = mb_clean_frame['CCS'].std()\n",
    "\n",
    "# Delete the raw data frame to save memory\n",
    "del mb_raw_data\n",
    "# randomize data set\n",
    "mb_clean_frame = mb_clean_frame.sample(frac=1, random_state=1)"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T09:20:59.948203Z",
     "start_time": "2023-10-09T09:20:57.825645Z"
    }
   },
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Split the data into input (m/z) and output (CCS) variables\n",
    "X = mb_clean_frame[['Mass', 'Charge', 'Length']]\n",
    "y = mb_clean_frame['CCS_z']\n",
    "# Define the number of folds\n",
    "k = 4\n",
    "# Number of trees\n",
    "n = 50"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-09T09:23:22.773765Z",
     "start_time": "2023-10-09T09:23:22.767746Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape mismatch: if categories is an array, it has to be of shape (n_features,).",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[0;32mIn [7]\u001B[0m, in \u001B[0;36m<cell line: 20>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     17\u001B[0m sequences \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(sequences)\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     19\u001B[0m \u001B[38;5;66;03m# Perform one-hot encoding\u001B[39;00m\n\u001B[0;32m---> 20\u001B[0m X_encoded \u001B[38;5;241m=\u001B[39m \u001B[43mencoder\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_transform\u001B[49m\u001B[43m(\u001B[49m\u001B[43msequences\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;66;03m# Replace X with the encoded sequences\u001B[39;00m\n\u001B[1;32m     24\u001B[0m X \u001B[38;5;241m=\u001B[39m X_encoded\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:855\u001B[0m, in \u001B[0;36mOneHotEncoder.fit_transform\u001B[0;34m(self, X, y)\u001B[0m\n\u001B[1;32m    833\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    834\u001B[0m \u001B[38;5;124;03mFit OneHotEncoder to X, then transform X.\u001B[39;00m\n\u001B[1;32m    835\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    852\u001B[0m \u001B[38;5;124;03m    returned.\u001B[39;00m\n\u001B[1;32m    853\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    854\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_keywords()\n\u001B[0;32m--> 855\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_transform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:867\u001B[0m, in \u001B[0;36mTransformerMixin.fit_transform\u001B[0;34m(self, X, y, **fit_params)\u001B[0m\n\u001B[1;32m    863\u001B[0m \u001B[38;5;66;03m# non-optimized default implementation; override when a better\u001B[39;00m\n\u001B[1;32m    864\u001B[0m \u001B[38;5;66;03m# method is possible for a given clustering algorithm\u001B[39;00m\n\u001B[1;32m    865\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m y \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    866\u001B[0m     \u001B[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001B[39;00m\n\u001B[0;32m--> 867\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_params\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mtransform(X)\n\u001B[1;32m    868\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    869\u001B[0m     \u001B[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001B[39;00m\n\u001B[1;32m    870\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfit(X, y, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_params)\u001B[38;5;241m.\u001B[39mtransform(X)\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:818\u001B[0m, in \u001B[0;36mOneHotEncoder.fit\u001B[0;34m(self, X, y)\u001B[0m\n\u001B[1;32m    800\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    801\u001B[0m \u001B[38;5;124;03mFit OneHotEncoder to X.\u001B[39;00m\n\u001B[1;32m    802\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    815\u001B[0m \u001B[38;5;124;03m    Fitted encoder.\u001B[39;00m\n\u001B[1;32m    816\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    817\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_keywords()\n\u001B[0;32m--> 818\u001B[0m fit_results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    819\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    820\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhandle_unknown\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhandle_unknown\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    821\u001B[0m \u001B[43m    \u001B[49m\u001B[43mforce_all_finite\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mallow-nan\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    822\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_counts\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_infrequent_enabled\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    823\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    824\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_infrequent_enabled:\n\u001B[1;32m    825\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fit_infrequent_category_mapping(\n\u001B[1;32m    826\u001B[0m         fit_results[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mn_samples\u001B[39m\u001B[38;5;124m\"\u001B[39m], fit_results[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcategory_counts\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m    827\u001B[0m     )\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:87\u001B[0m, in \u001B[0;36m_BaseEncoder._fit\u001B[0;34m(self, X, handle_unknown, force_all_finite, return_counts)\u001B[0m\n\u001B[1;32m     85\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcategories \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mauto\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m     86\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcategories) \u001B[38;5;241m!=\u001B[39m n_features:\n\u001B[0;32m---> 87\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m     88\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mShape mismatch: if categories is an array,\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     89\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m it has to be of shape (n_features,).\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     90\u001B[0m         )\n\u001B[1;32m     92\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcategories_ \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m     93\u001B[0m category_counts \u001B[38;5;241m=\u001B[39m []\n",
      "\u001B[0;31mValueError\u001B[0m: Shape mismatch: if categories is an array, it has to be of shape (n_features,)."
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define the amino acids\n",
    "amino_acids = ['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y', 'U']\n",
    "\n",
    "# Initialize the one-hot encoder\n",
    "encoder = OneHotEncoder(categories=[amino_acids]*30, sparse=False)\n",
    "\n",
    "# Extract the sequences\n",
    "sequences = mb_clean_frame['Sequence']\n",
    "\n",
    "# Truncate or pad the sequences to a length of 30\n",
    "sequences = [seq[:30].ljust(30, '0') for seq in sequences]\n",
    "\n",
    "# Convert the sequences to a 2D array\n",
    "sequences = np.array(sequences).reshape(-1, 1)\n",
    "\n",
    "# Perform one-hot encoding\n",
    "X_encoded = encoder.fit_transform(sequences)\n",
    "\n",
    "\n",
    "# Replace X with the encoded sequences\n",
    "X = X_encoded\n",
    "\n",
    "# Initialize the progress bar\n",
    "pbar = tqdm(total=k)\n",
    "start_time = time.time()\n",
    "# Initialize the cross-validation object\n",
    "kf = KFold(n_splits=k)\n",
    "# Initialize a list to store the MSE for each fold\n",
    "mse_scores = []\n",
    "median_relative_errors = []\n",
    "r2_scores = []\n",
    "# Perform k-fold cross-validation with progress bar\n",
    "for train_index, test_index in kf.split(X):\n",
    "    # Update the progress bar\n",
    "    pbar.update(1)\n",
    "    # ... rest of your code ...\n",
    "    # Split the data into training and testing sets for the current fold\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    # Create a random forest regressor model\n",
    "    model = RandomForestRegressor(n_estimators=n, random_state=1,n_jobs=-1)\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Convert predictions back to original scale\n",
    "    y_pred_orig = y_pred * ccs_std + ccs_mean\n",
    "    y_test_orig = y_test * ccs_std + ccs_mean\n",
    "\n",
    "    # Calculate the MSE for the current fold\n",
    "    mse = mean_squared_error(y_test_orig, y_pred_orig)\n",
    "    mse_scores.append(mse)\n",
    "    # Calculate the median relative error for the current fold\n",
    "    relative_errors = np.abs((y_pred_orig - y_test_orig) / y_test_orig)\n",
    "    median_relative_error = np.median(relative_errors)\n",
    "    median_relative_errors.append(median_relative_error)\n",
    "    # Calculate the R^2 score for the current fold\n",
    "    r2 = r2_score(y_test_orig, y_pred_orig)\n",
    "    r2_scores.append(r2)\n",
    "    # Progress update\n",
    "    print(\"Fold:\", len(mse_scores))\n",
    "# Close the progress bar\n",
    "pbar.close()\n",
    "# Create the final model\n",
    "final_model = RandomForestRegressor(n_estimators=n, random_state=1,n_jobs=-1)\n",
    "final_model.fit(X, y)\n",
    "\n",
    "# Print the average MSE score\n",
    "print(\"Average Mean Squared Error:\", np.mean(mse_scores))\n",
    "# print the average of the median relative errors\n",
    "print(\"Average Median Relative Error:\", np.mean(median_relative_errors))\n",
    "# Print the average R^2 score\n",
    "print(\"Average R^2 Score:\", np.mean(r2_scores))\n",
    "# Calculate the elapsed time\n",
    "elapsed_time = time.time() - start_time\n",
    "# Print the elapsed time\n",
    "print(f'Time elapsed: {elapsed_time:.2f} seconds')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-09T09:24:13.525755Z",
     "start_time": "2023-10-09T09:24:13.388109Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform k-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start logging time in ms without\n",
    "start_time = time.time()\n",
    "# Initialize the cross-validation object\n",
    "kf = KFold(n_splits=k)\n",
    "# Initialize a list to store the MSE for each fold\n",
    "mse_scores = []\n",
    "median_relative_errors = []\n",
    "r2_scores = []\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in kf.split(X):\n",
    "    # Split the data into training and testing sets for the current fold\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    # Create a random forest regressor model\n",
    "    model = RandomForestRegressor(n_estimators=n, random_state=1,n_jobs=-1)\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Convert predictions back to original scale\n",
    "    y_pred_orig = y_pred * ccs_std + ccs_mean\n",
    "    y_test_orig = y_test * ccs_std + ccs_mean\n",
    "\n",
    "    # Calculate the MSE for the current fold\n",
    "    mse = mean_squared_error(y_test_orig, y_pred_orig)\n",
    "    mse_scores.append(mse)\n",
    "    # Calculate the median relative error for the current fold\n",
    "    relative_errors = np.abs((y_pred_orig - y_test_orig) / y_test_orig)\n",
    "    median_relative_error = np.median(relative_errors)\n",
    "    median_relative_errors.append(median_relative_error)\n",
    "    # Calculate the R^2 score for the current fold\n",
    "    r2 = r2_score(y_test_orig, y_pred_orig)\n",
    "    r2_scores.append(r2)\n",
    "    # Progress update\n",
    "    print(\"Fold:\", len(mse_scores))\n",
    "\n",
    "# Create the final model\n",
    "final_model = RandomForestRegressor(n_estimators=n, random_state=1,n_jobs=-1)\n",
    "final_model.fit(X, y)\n",
    "\n",
    "# Print the average MSE score\n",
    "print(\"Average Mean Squared Error:\", np.mean(mse_scores))\n",
    "# print the average of the median relative errors\n",
    "print(\"Average Median Relative Error:\", np.mean(median_relative_errors))\n",
    "# Print the average R^2 score\n",
    "print(\"Average R^2 Score:\", np.mean(r2_scores))\n",
    "# Calculate the elapsed time\n",
    "elapsed_time = time.time() - start_time\n",
    "# Print the elapsed time\n",
    "print(f'Time elapsed: {elapsed_time:.2f} seconds')"
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h8/62vn1gzj3456t6qsdpq7mx3w0000gn/T/ipykernel_10599/1774603528.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mb_clean_frame['CCS_z'] = stats.zscore(mb_clean_frame['CCS'])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score, KFold, learning_curve\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tqdm import tqdm  # For the progress bar\n",
    "\n",
    "# Load the data\n",
    "mb_raw_data = pd.read_csv('../../data/mann_bruker.txt', sep='\\t')\n",
    "\n",
    "# Keep only necessary columns\n",
    "mb_clean_frame = mb_raw_data[['Sequence', 'm/z', 'CCS', 'Mass', 'Charge', 'Length']]\n",
    "\n",
    "# Perform z-score transformation\n",
    "mb_clean_frame['CCS_z'] = stats.zscore(mb_clean_frame['CCS'])\n",
    "\n",
    "# Save the mean and std for later use\n",
    "ccs_mean = mb_clean_frame['CCS'].mean()\n",
    "ccs_std = mb_clean_frame['CCS'].std()\n",
    "\n",
    "# Delete the raw data frame to save memory\n",
    "del mb_raw_data\n",
    "\n",
    "# randomize data set\n",
    "mb_clean_frame = mb_clean_frame.sample(frac=1, random_state=1)\n",
    "\n",
    "# One-hot encode the 'Sequence' column\n",
    "encoder = OneHotEncoder(sparse=False, dtype=int, handle_unknown='ignore')\n",
    "sequence_encoded = pd.DataFrame(encoder.fit_transform(mb_clean_frame[['Sequence']]))\n",
    "\n",
    "# Concatenate the one-hot-encoded sequence with the existing features\n",
    "X_encoded = pd.concat([sequence_encoded, mb_clean_frame[['Mass', 'Charge', 'Length']]], axis=1)\n",
    "\n",
    "# Split the data into input (m/z) and output (CCS) variables\n",
    "X = X_encoded\n",
    "y = mb_clean_frame['CCS_z']\n",
    "\n",
    "# Define the number of folds\n",
    "k = 4\n",
    "# Number of trees\n",
    "n = 50\n",
    "\n",
    "# Start logging time in ms without\n",
    "start_time = time.time()\n",
    "# Initialize the cross-validation object\n",
    "kf = KFold(n_splits=k)\n",
    "# Initialize a list to store the MSE for each fold\n",
    "mse_scores = []\n",
    "median_relative_errors = []\n",
    "r2_scores = []\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X_encoded)):\n",
    "    # Split the data into training and testing sets for the current fold\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    # Create a random forest regressor model\n",
    "    model = RandomForestRegressor(n_estimators=n, random_state=1, n_jobs=-1)\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Convert predictions back to the original scale\n",
    "    y_pred_orig = y_pred * ccs_std + ccs_mean\n",
    "    y_test_orig = y_test * ccs_std + ccs_mean\n",
    "\n",
    "    # Calculate the MSE for the current fold\n",
    "    mse = mean_squared_error(y_test_orig, y_pred_orig)\n",
    "    mse_scores.append(mse)\n",
    "    # Calculate the median relative error for the current fold\n",
    "    relative_errors = np.abs((y_pred_orig - y_test_orig) / y_test_orig)\n",
    "    median_relative_error = np.median(relative_errors)\n",
    "    median_relative_errors.append(median_relative_error)\n",
    "    # Calculate the R^2 score for the current fold\n",
    "    r2 = r2_score(y_test_orig, y_pred_orig)\n",
    "    r2_scores.append(r2)\n",
    "    # Progress update with a progress bar\n",
    "    tqdm.write(f\"Fold: {fold + 1}/{k}\")\n",
    "\n",
    "# Create the final model\n",
    "final_model = RandomForestRegressor(n_estimators=n, random_state=1, n_jobs=-1)\n",
    "final_model.fit(X, y)\n",
    "\n",
    "# Print the average MSE score\n",
    "print(\"Average Mean Squared Error:\", np.mean(mse_scores))\n",
    "# Print the average of the median relative errors\n",
    "print(\"Average Median Relative Error:\", np.mean(median_relative_errors))\n",
    "# Print the average R^2 score\n",
    "print(\"Average R^2 Score:\", np.mean(r2_scores))\n",
    "# Calculate the elapsed time\n",
    "elapsed_time = time.time() - start_time\n",
    "# Print the elapsed time\n",
    "print(f'Time elapsed: {elapsed_time:.2f} seconds')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-09T09:16:53.981461Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "# Define the sizes of the training sets to use\n",
    "train_sizes = np.linspace(0.1, 1.0, 10)\n",
    "# Calculate the learning curve\n",
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "    RandomForestRegressor(n_estimators=n, random_state=1,n_jobs=-1),\n",
    "    X,\n",
    "    y,\n",
    "    train_sizes=train_sizes,\n",
    "    cv=k,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Calculate the average training and test scores\n",
    "train_scores_mean = -np.mean(train_scores, axis=1)\n",
    "test_scores_mean = -np.mean(test_scores, axis=1)\n",
    "\n",
    "# Plot the learning curve\n",
    "plt.plot(train_sizes, train_scores_mean, label='Training score')\n",
    "plt.plot(train_sizes, test_scores_mean, label='Test score')\n",
    "plt.xlabel('Training set size')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Save the model to a file\n",
    "#filename = 'random_forest'\n",
    "#pickle.dump(model, open(filename, 'wb'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Predict the CCS of the peptides in the data frame\n",
    "mb_clean_frame['Predicted CCS'] = final_model.predict(X)\n",
    "\n",
    "# Reverse the z-score transformation\n",
    "mb_clean_frame['Predicted CCS'] = mb_clean_frame['Predicted CCS'] * ccs_std + ccs_mean\n"
   ],
   "outputs": [],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatter plot of the error between the predicted and actual CCS values by sequence length. X = Experimental CCS, Y = Predicted CCS, Color = Sequence Length, Colormap = cool, alpha = 0.01\n",
    "mb_clean_frame.plot.scatter(\n",
    "    x='CCS',\n",
    "    y='Predicted CCS',\n",
    "    c='Length',\n",
    "    cmap='winter',\n",
    "    alpha=0.2,\n",
    "    vmin=mb_clean_frame['Length'].min(),\n",
    "    vmax=mb_clean_frame['Length'].max()\n",
    ")\n",
    "mb_clean_frame.plot.hexbin(\n",
    "    x='CCS',\n",
    "    y='Predicted CCS',\n",
    "    C='Length',\n",
    "    reduce_C_function=np.mean,\n",
    "    gridsize=50,\n",
    "    cmap='magma'\n",
    ")\n",
    "\n",
    "# Print the Spearman's correlation coefficient between the predicted and actual CCS values\n",
    "print(\"Spearman's Correlation Coefficient:\", mb_clean_frame['CCS'].corr(mb_clean_frame['Predicted CCS'], method='spearman'))\n",
    "# Create a scatter plot between the percent error and length\n",
    "mb_clean_frame['Percent Error'] = np.abs((mb_clean_frame['Predicted CCS'] - mb_clean_frame['CCS']) / mb_clean_frame['CCS'])\n",
    "mb_clean_frame.plot.scatter(\n",
    "    x='Length',\n",
    "    y='Percent Error',\n",
    "    alpha=0.2,\n",
    "    vmin=mb_clean_frame['Length'].min(),\n",
    "    vmax=mb_clean_frame['Length'].max()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get the importances from the final model\n",
    "importances = final_model.feature_importances_\n",
    "# Sort the feature importances in descending order\n",
    "indices = np.argsort(importances)[::-1]\n",
    "features = X.columns\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Feature Importance\")\n",
    "plt.bar(range(X.shape[1]), importances[indices], color=\"#3070B3\", align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), features[indices], rotation=0)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.ylabel('Feature Importance')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
