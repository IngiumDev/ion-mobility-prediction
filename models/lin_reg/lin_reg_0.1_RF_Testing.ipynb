{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from scipy import stats"
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load  data into a  DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load the data\n",
    "mb_raw_data = pd.read_csv('../../data/mann_bruker.txt', sep='\\t')\n",
    "\n",
    "# Keep only necessary columns\n",
    "mb_clean_frame = mb_raw_data[['Sequence', 'm/z', 'CCS','Mass','Charge','Length']]\n",
    "\n",
    "# Perform z-score transformation\n",
    "mb_clean_frame['CCS_z'] = stats.zscore(mb_clean_frame['CCS'])\n",
    "\n",
    "# Save the mean and std for later use\n",
    "ccs_mean = mb_clean_frame['CCS'].mean()\n",
    "ccs_std = mb_clean_frame['CCS'].std()\n",
    "\n",
    "# Delete the raw data frame to save memory\n",
    "del mb_raw_data\n",
    "# randomize data set\n",
    "mb_clean_frame = mb_clean_frame.sample(frac=1, random_state=1)"
   ],
   "metadata": {},
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Split the data into input (m/z) and output (CCS) variables\n",
    "X = mb_clean_frame[[\"Charge\", 'Mass', 'Length']]\n",
    "y = mb_clean_frame['CCS_z']\n",
    "\n",
    "# Split the data into training and test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# create dataframe for test data\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "y_test_df = pd.DataFrame(y_test)\n",
    "\n",
    "# Define the number of folds\n",
    "k = 4"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# all test data in one df\n",
    "test_data = pd.concat([X_test_df, y_test_df], axis=1)\n",
    "\n",
    "# add CCS column for later correlation check\n",
    "ccs_test = mb_clean_frame['CCS'].loc[X_test_df.index]\n",
    "\n",
    "# Add the ccs values to your test DataFrame\n",
    "test_data = pd.concat([test_data, ccs_test], axis=1)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "        Charge         Mass  Length     CCS_z           CCS\n28937        1   856.513051     7.0 -1.263315  5.857853e-36\n178499       2  1114.635960     9.0  0.359633  1.914299e-35\n90066        1   714.402438     7.0 -1.173393  6.593936e-36\n4076         1   826.370863     7.0 -1.215553  6.248821e-36\n109119       2  1057.576770     9.0  0.448123  1.986735e-35\n...        ...          ...     ...       ...           ...\n168128       2  2602.053910    23.0 -0.525002  1.190154e-35\n58756        2  1959.943420    16.0 -0.261243  1.406062e-35\n112357       3  1430.700140    12.0  2.037570  3.287826e-35\n145151       2  1172.614950    10.0  0.293103  1.859839e-35\n41294        1   941.424296     7.0 -1.266643  5.830605e-36\n\n[46323 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Charge</th>\n      <th>Mass</th>\n      <th>Length</th>\n      <th>CCS_z</th>\n      <th>CCS</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>28937</th>\n      <td>1</td>\n      <td>856.513051</td>\n      <td>7.0</td>\n      <td>-1.263315</td>\n      <td>5.857853e-36</td>\n    </tr>\n    <tr>\n      <th>178499</th>\n      <td>2</td>\n      <td>1114.635960</td>\n      <td>9.0</td>\n      <td>0.359633</td>\n      <td>1.914299e-35</td>\n    </tr>\n    <tr>\n      <th>90066</th>\n      <td>1</td>\n      <td>714.402438</td>\n      <td>7.0</td>\n      <td>-1.173393</td>\n      <td>6.593936e-36</td>\n    </tr>\n    <tr>\n      <th>4076</th>\n      <td>1</td>\n      <td>826.370863</td>\n      <td>7.0</td>\n      <td>-1.215553</td>\n      <td>6.248821e-36</td>\n    </tr>\n    <tr>\n      <th>109119</th>\n      <td>2</td>\n      <td>1057.576770</td>\n      <td>9.0</td>\n      <td>0.448123</td>\n      <td>1.986735e-35</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>168128</th>\n      <td>2</td>\n      <td>2602.053910</td>\n      <td>23.0</td>\n      <td>-0.525002</td>\n      <td>1.190154e-35</td>\n    </tr>\n    <tr>\n      <th>58756</th>\n      <td>2</td>\n      <td>1959.943420</td>\n      <td>16.0</td>\n      <td>-0.261243</td>\n      <td>1.406062e-35</td>\n    </tr>\n    <tr>\n      <th>112357</th>\n      <td>3</td>\n      <td>1430.700140</td>\n      <td>12.0</td>\n      <td>2.037570</td>\n      <td>3.287826e-35</td>\n    </tr>\n    <tr>\n      <th>145151</th>\n      <td>2</td>\n      <td>1172.614950</td>\n      <td>10.0</td>\n      <td>0.293103</td>\n      <td>1.859839e-35</td>\n    </tr>\n    <tr>\n      <th>41294</th>\n      <td>1</td>\n      <td>941.424296</td>\n      <td>7.0</td>\n      <td>-1.266643</td>\n      <td>5.830605e-36</td>\n    </tr>\n  </tbody>\n</table>\n<p>46323 rows Ã— 5 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform k-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1\n",
      "Fold: 2\n",
      "Fold: 3\n",
      "Fold: 4\n",
      "Average Mean Squared Error: 1.1197322962231657e-72\n",
      "Average Median Relative Error: 0.03321281303928507\n",
      "Average R^2 Score: 0.9832896122833029\n",
      "Time elapsed: 0.62 seconds\n"
     ]
    }
   ],
   "source": [
    "# Start logging time in ms without\n",
    "start_time = time.time()\n",
    "# Initialize the cross-validation object\n",
    "kf = KFold(n_splits=k)\n",
    "# Initialize a list to store the MSE for each fold\n",
    "mse_scores = []\n",
    "median_relative_errors = []\n",
    "r2_scores = []\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in kf.split(X):\n",
    "    # Split the data into training and testing sets for the current fold\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    # Create a linear regression model\n",
    "    model = LinearRegression(n_jobs=-1)\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Convert predictions back to original scale\n",
    "    y_pred_orig = y_pred * ccs_std + ccs_mean\n",
    "    y_test_orig = y_test * ccs_std + ccs_mean\n",
    "\n",
    "    # Calculate the MSE for the current fold\n",
    "    mse = mean_squared_error(y_test_orig, y_pred_orig)\n",
    "    mse_scores.append(mse)\n",
    "    # Calculate the median relative error for the current fold\n",
    "    relative_errors = np.abs((y_pred_orig - y_test_orig) / y_test_orig)\n",
    "    median_relative_error = np.median(relative_errors)\n",
    "    median_relative_errors.append(median_relative_error)\n",
    "    # Calculate the R^2 score for the current fold\n",
    "    r2 = r2_score(y_test_orig, y_pred_orig)\n",
    "    r2_scores.append(r2)\n",
    "    # Progress update\n",
    "    print(\"Fold:\", len(mse_scores))\n",
    "\n",
    "# Create the final model\n",
    "final_model = LinearRegression(n_jobs=-1)\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "# Print the average MSE score\n",
    "print(\"Average Mean Squared Error:\", np.mean(mse_scores))\n",
    "# print the average of the median relative errors\n",
    "print(\"Average Median Relative Error:\", np.mean(median_relative_errors))\n",
    "# Print the average R^2 score\n",
    "print(\"Average R^2 Score:\", np.mean(r2_scores))\n",
    "# Calculate the elapsed time\n",
    "elapsed_time = time.time() - start_time\n",
    "# Print the elapsed time\n",
    "print(f'Time elapsed: {elapsed_time:.2f} seconds')\n"
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1\n",
      "Fold: 2\n",
      "Fold: 3\n",
      "Fold: 4\n",
      "prediction:  173709 y training:  173709 x training:  173709\n",
      "Average Corrected Mean Squared Error: 7.385393432772418e-73\n",
      "Average Corrected Median Relative Error: 0.01704531763387187\n",
      "Average Corrected R^2 Score: 0.9889782737598579\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the number of folds\n",
    "k = 4\n",
    "\n",
    "# Define the number of trees in the random forest\n",
    "n = 50\n",
    "\n",
    "# Initialize the cross-validation object\n",
    "kf = KFold(n_splits=k)\n",
    "\n",
    "# Initialize lists to store the corrected MSE, median relative error and R^2 score for each fold\n",
    "corrected_mse_scores = []\n",
    "corrected_median_relative_errors = []\n",
    "corrected_r2_scores = []\n",
    "y_pred = final_model.predict(X_train)\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in kf.split(X):\n",
    "    # Progress update\n",
    "    print(\"Fold:\", len(corrected_mse_scores) + 1)\n",
    "    # Split the data into training and testing sets for the current fold\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Predict the CCS values on the training set\n",
    "    y_train_pred = final_model.predict(X_train)\n",
    "\n",
    "    # Calculate the residuals from the linear regression model\n",
    "    residuals = y_train - y_train_pred\n",
    "\n",
    "    # Train a RF model on the residuals\n",
    "    rf_model = RandomForestRegressor(n_estimators=n, n_jobs=-1)\n",
    "    rf_model.fit(X_train, residuals)\n",
    "\n",
    "    # Predict the residuals on the test set\n",
    "    residuals_pred = rf_model.predict(X_test)\n",
    "    \n",
    "    # Predict the CCS values on the test set\n",
    "    y_test_pred = final_model.predict(X_test)\n",
    "    # Correct the initial predictions with the predicted residuals\n",
    "    corrected_y_pred = y_test_pred + residuals_pred\n",
    "    \n",
    "    # Convert predictions back to original scale\n",
    "    y_pred_orig = corrected_y_pred * ccs_std + ccs_mean\n",
    "    y_test_orig = y_test * ccs_std + ccs_mean\n",
    "    \n",
    "    # Calculate the corrected MSE, median relative error and R^2 score for the current fold\n",
    "    corrected_mse = mean_squared_error(y_test_orig, y_pred_orig)\n",
    "    corrected_relative_errors = np.abs((y_pred_orig - y_test_orig) / y_test_orig)\n",
    "    corrected_median_relative_error = np.median(corrected_relative_errors)\n",
    "    corrected_r2 = r2_score(y_test_orig, y_pred_orig)\n",
    "\n",
    "\n",
    "    # Append the scores to their respective lists\n",
    "    corrected_mse_scores.append(corrected_mse)\n",
    "    corrected_median_relative_errors.append(corrected_median_relative_error)\n",
    "    corrected_r2_scores.append(corrected_r2)\n",
    "\n",
    "# Create the final model\n",
    "print(\"prediction: \", len(y_pred), \"y training: \", len(y_train), \"x training: \", len(X_train))\n",
    "final_residual_model = RandomForestRegressor(n_estimators=n, n_jobs=-1)\n",
    "final_residual_model.fit(X_train, y_train - y_pred)\n",
    "# Print the average corrected MSE, median relative error and R^2 score\n",
    "print(\"Average Corrected Mean Squared Error:\", np.mean(corrected_mse_scores))\n",
    "print(\"Average Corrected Median Relative Error:\", np.mean(corrected_median_relative_errors))\n",
    "print(\"Average Corrected R^2 Score:\", np.mean(corrected_r2_scores))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (57902) does not match length of index (46323)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Predict the CCS (corrected) of the peptides in the data frame with the test data\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m \u001B[43mtest_data\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mPredicted CCS Corrected\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m \u001B[38;5;241m=\u001B[39m final_model\u001B[38;5;241m.\u001B[39mpredict(X_test) \u001B[38;5;241m+\u001B[39m final_residual_model\u001B[38;5;241m.\u001B[39mpredict(X_test)\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m# Reverse the z-score transformation\u001B[39;00m\n\u001B[0;32m      5\u001B[0m test_data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mPredicted CCS Corrected\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m test_data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mPredicted CCS Corrected\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m*\u001B[39m ccs_std \u001B[38;5;241m+\u001B[39m ccs_mean\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\frame.py:4091\u001B[0m, in \u001B[0;36mDataFrame.__setitem__\u001B[1;34m(self, key, value)\u001B[0m\n\u001B[0;32m   4088\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_setitem_array([key], value)\n\u001B[0;32m   4089\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   4090\u001B[0m     \u001B[38;5;66;03m# set column\u001B[39;00m\n\u001B[1;32m-> 4091\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_set_item\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\frame.py:4300\u001B[0m, in \u001B[0;36mDataFrame._set_item\u001B[1;34m(self, key, value)\u001B[0m\n\u001B[0;32m   4290\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_set_item\u001B[39m(\u001B[38;5;28mself\u001B[39m, key, value) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   4291\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   4292\u001B[0m \u001B[38;5;124;03m    Add series to DataFrame in specified column.\u001B[39;00m\n\u001B[0;32m   4293\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   4298\u001B[0m \u001B[38;5;124;03m    ensure homogeneity.\u001B[39;00m\n\u001B[0;32m   4299\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 4300\u001B[0m     value, refs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sanitize_column\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   4302\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m   4303\u001B[0m         key \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\n\u001B[0;32m   4304\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m value\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m   4305\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(value\u001B[38;5;241m.\u001B[39mdtype, ExtensionDtype)\n\u001B[0;32m   4306\u001B[0m     ):\n\u001B[0;32m   4307\u001B[0m         \u001B[38;5;66;03m# broadcast across multiple columns if necessary\u001B[39;00m\n\u001B[0;32m   4308\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mis_unique \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns, MultiIndex):\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\frame.py:5039\u001B[0m, in \u001B[0;36mDataFrame._sanitize_column\u001B[1;34m(self, value)\u001B[0m\n\u001B[0;32m   5036\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _reindex_for_setitem(value, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindex)\n\u001B[0;32m   5038\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_list_like(value):\n\u001B[1;32m-> 5039\u001B[0m     \u001B[43mcom\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequire_length_match\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   5040\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m sanitize_array(value, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindex, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, allow_2d\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m), \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\common.py:561\u001B[0m, in \u001B[0;36mrequire_length_match\u001B[1;34m(data, index)\u001B[0m\n\u001B[0;32m    557\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    558\u001B[0m \u001B[38;5;124;03mCheck the length of data matches the length of the index.\u001B[39;00m\n\u001B[0;32m    559\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    560\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(data) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mlen\u001B[39m(index):\n\u001B[1;32m--> 561\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    562\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLength of values \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    563\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m(\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(data)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m) \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    564\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdoes not match length of index \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    565\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m(\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(index)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m)\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    566\u001B[0m     )\n",
      "\u001B[1;31mValueError\u001B[0m: Length of values (57902) does not match length of index (46323)"
     ]
    }
   ],
   "source": [
    "# Predict the CCS (corrected) of the peptides in the data frame with the test data\n",
    "test_data['Predicted CCS Corrected'] = final_model.predict(X_test) + final_residual_model.predict(X_test)\n",
    "\n",
    "# Reverse the z-score transformation\n",
    "test_data['Predicted CCS Corrected'] = test_data['Predicted CCS Corrected'] * ccs_std + ccs_mean\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# final model parameters Ensemble Model\n",
    "r2 = r2_score(test_data['CCS'], test_data['Predicted CCS Corrected'])\n",
    "mse = mean_squared_error(test_data['CCS'], test_data['Predicted CCS Corrected'])\n",
    "relative_errors = np.abs((test_data['Predicted CCS Corrected'] - test_data['CCS']) / test_data['CCS'])\n",
    "median_relative_error = np.median(relative_errors)\n",
    "print(\"Average Corrected Mean Squared Error:\", np.mean(mse))\n",
    "print(\"Average Corrected Median Relative Error:\", median_relative_error)\n",
    "print(\"Average Corrected R^2 Score:\", np.mean(r2))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create a scatter plot of the error between the predicted and actual CCS values by sequence length. X = Experimental CCS, Y = Predicted CCS, Color = Sequence Length, Colormap = cool, alpha = 0.01\n",
    "test_data.plot.scatter(\n",
    "    x='CCS',\n",
    "    y='Predicted CCS Corrected',\n",
    "    c='Length',\n",
    "    cmap='winter',\n",
    "    alpha=0.2,\n",
    "    vmin=mb_clean_frame['Length'].min(),\n",
    "    vmax=mb_clean_frame['Length'].max()\n",
    ")\n",
    "test_data.plot.hexbin(\n",
    "    x='CCS',\n",
    "    y='Predicted CCS Corrected',\n",
    "    C='Length',\n",
    "    reduce_C_function=np.mean,\n",
    "    gridsize=50,\n",
    "    cmap='magma'\n",
    ")\n",
    "\n",
    "# Print the Spearman's  & Pearson's correlation coefficient between the predicted and actual CCS values\n",
    "# Spearman uses rank (assumes a monotonic function), Pearson uses covariance and std to assess linear correlation\n",
    "print(\"Spearman's Correlation Coefficient:\", test_data['CCS'].corr(test_data['Predicted CCS Corrected'], method='spearman'))\n",
    "print(\"Pearson's Correlation Coefficient:\", test_data['CCS'].corr(test_data['Predicted CCS Corrected'], method='pearson'))\n",
    "print(\"This is correlation on the test dataset, which has size:\", len(test_data), \"\\n\", \"the whole dataset is\", len(X))\n",
    "\n",
    "# Create a scatter plot between the percent error and length\n",
    "test_data['Percent Error'] = np.abs((test_data['Predicted CCS Corrected'] - test_data['CCS']) / test_data['CCS'])\n",
    "test_data.plot.scatter(\n",
    "    x='Length',\n",
    "    y='Percent Error',\n",
    "    alpha=0.2,\n",
    "    vmin=mb_clean_frame['Length'].min(),\n",
    "    vmax=mb_clean_frame['Length'].max()\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# parameters of final model\n",
    "final_model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "# TODO: CHECK LEARNING CURVE AGAIN\n",
    "# Define the sizes of the training sets to use\n",
    "train_sizes = np.linspace(0.1, 1.0, 10)\n",
    "\n",
    "# Calculate the learning curve\n",
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "    LinearRegression(n_jobs=-1),\n",
    "    X,\n",
    "    y,\n",
    "    train_sizes=train_sizes,\n",
    "    cv=k,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Calculate the average training and test scores\n",
    "train_scores_mean = -np.mean(train_scores, axis=1)\n",
    "test_scores_mean = -np.mean(test_scores, axis=1)\n",
    "\n",
    "# Plot the learning curve\n",
    "plt.plot(train_sizes, train_scores_mean, label='Training score')\n",
    "plt.plot(train_sizes, test_scores_mean, label='Cross-validation score')\n",
    "plt.xlabel('Training set size')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "importance = model.coef_\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    " print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "\n",
    "# plot feature importance\n",
    "plt.bar([x for x in range(len(importance))], importance, color=\"#3070B3\")\n",
    "plt.title(\"Feature Importance\")\n",
    "features = X.columns\n",
    "plt.xticks(range(X.shape[1]), model.feature_names_in_, rotation=0)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Predict the CCS of the peptides in the data frame for whole data, on whole model\n",
    "mb_clean_frame['Predicted CCS'] = final_model.predict(X)\n",
    "\n",
    "# Reverse the z-score transformation\n",
    "mb_clean_frame['Predicted CCS'] = mb_clean_frame['Predicted CCS'] * ccs_std + ccs_mean\n"
   ],
   "outputs": [],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create a scatter plot of the error between the predicted and actual CCS values by sequence length. X = Experimental CCS, Y = Predicted CCS, Color = Sequence Length, Colormap = cool, alpha = 0.01\n",
    "mb_clean_frame.plot.scatter(\n",
    "    x='CCS',\n",
    "    y='Predicted CCS',\n",
    "    c='Length',\n",
    "    cmap='winter',\n",
    "    alpha=0.2,\n",
    "    vmin=mb_clean_frame['Length'].min(),\n",
    "    vmax=mb_clean_frame['Length'].max()\n",
    ")\n",
    "mb_clean_frame.plot.hexbin(\n",
    "    x='CCS',\n",
    "    y='Predicted CCS',\n",
    "    C='Length',\n",
    "    reduce_C_function=np.mean,\n",
    "    gridsize=50,\n",
    "    cmap='magma'\n",
    ")\n",
    "\n",
    "# Print the Spearman's correlation coefficient between the predicted and actual CCS values\n",
    "print(\"Spearman's Correlation Coefficient:\", mb_clean_frame['CCS'].corr(mb_clean_frame['Predicted CCS'], method='spearman'))\n",
    "print(\"Pearson's Correlation Coefficient:\", mb_clean_frame['CCS'].corr(mb_clean_frame['Predicted CCS'], method='pearson'))\n",
    "\n",
    "# Create a scatter plot between the percent error and length\n",
    "mb_clean_frame['Percent Error'] = np.abs((mb_clean_frame['Predicted CCS'] - mb_clean_frame['CCS']) / mb_clean_frame['CCS'])\n",
    "mb_clean_frame.plot.scatter(\n",
    "    x='Length',\n",
    "    y='Percent Error',\n",
    "    alpha=0.2,\n",
    "    vmin=mb_clean_frame['Length'].min(),\n",
    "    vmax=mb_clean_frame['Length'].max()\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Save the model to a file"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#filename = '../../models/lin_reg/lin_reg.pkl'\n",
    "#pickle.dump(model, open(filename, 'wb'))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
