{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-09T11:56:13.296319Z",
     "start_time": "2023-10-09T11:56:10.361922Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import matplotlib.colors as colors"
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load  data into a  DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load the data\n",
    "mb_raw_data = pd.read_csv('../../data/mann_bruker.txt', sep='\\t')\n",
    "\n",
    "# Keep only necessary columns\n",
    "mb_clean_frame = mb_raw_data[['Sequence', 'm/z', 'CCS','Mass','Charge','Length']]\n",
    "# Group by 'Sequence' and 'Charge', and calculate median of 'Mass' and 'CCS'\n",
    "mb_clean_frame = mb_clean_frame.groupby(['Sequence', 'Charge']).agg({'Mass':'median', 'CCS':'median','Length':'median'}).reset_index()\n",
    "# Perform z-score transformation\n",
    "mb_clean_frame['CCS_z'] = stats.zscore(mb_clean_frame['CCS'])\n",
    "\n",
    "# Save the mean and std for later use\n",
    "ccs_mean = mb_clean_frame['CCS'].mean()\n",
    "ccs_std = mb_clean_frame['CCS'].std()\n",
    "\n",
    "# Delete the raw data frame to save memory\n",
    "del mb_raw_data\n",
    "# randomize data set\n",
    "mb_clean_frame = mb_clean_frame.sample(frac=1, random_state=1)"
   ],
   "metadata": {},
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Split the data into input (m/z) and output (CCS) variables\n",
    "X = mb_clean_frame[['Mass', 'Length']]\n",
    "y = mb_clean_frame['CCS_z']\n",
    "# Define the number of folds\n",
    "k = 4"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-09T11:56:16.244539Z",
     "start_time": "2023-10-09T11:56:16.241417Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform k-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T11:56:20.515179Z",
     "start_time": "2023-10-09T11:56:19.688287Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Python311\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 10 features, but LinearRegression is expecting 2 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 44\u001B[0m\n\u001B[0;32m     41\u001B[0m X_test_poly \u001B[38;5;241m=\u001B[39m poly\u001B[38;5;241m.\u001B[39mtransform(X_test)\n\u001B[0;32m     43\u001B[0m \u001B[38;5;66;03m# Make predictions on the test set\u001B[39;00m\n\u001B[1;32m---> 44\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_test_poly\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     46\u001B[0m \u001B[38;5;66;03m# Convert predictions back to original scale\u001B[39;00m\n\u001B[0;32m     47\u001B[0m y_pred_orig \u001B[38;5;241m=\u001B[39m y_pred \u001B[38;5;241m*\u001B[39m ccs_std \u001B[38;5;241m+\u001B[39m ccs_mean\n",
      "File \u001B[1;32mC:\\Program Files\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:386\u001B[0m, in \u001B[0;36mLinearModel.predict\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m    372\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpredict\u001B[39m(\u001B[38;5;28mself\u001B[39m, X):\n\u001B[0;32m    373\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    374\u001B[0m \u001B[38;5;124;03m    Predict using the linear model.\u001B[39;00m\n\u001B[0;32m    375\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    384\u001B[0m \u001B[38;5;124;03m        Returns predicted values.\u001B[39;00m\n\u001B[0;32m    385\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 386\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_decision_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Program Files\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:369\u001B[0m, in \u001B[0;36mLinearModel._decision_function\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m    366\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_decision_function\u001B[39m(\u001B[38;5;28mself\u001B[39m, X):\n\u001B[0;32m    367\u001B[0m     check_is_fitted(\u001B[38;5;28mself\u001B[39m)\n\u001B[1;32m--> 369\u001B[0m     X \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcsr\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcsc\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcoo\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m    370\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m safe_sparse_dot(X, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcoef_\u001B[38;5;241m.\u001B[39mT, dense_output\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m) \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mintercept_\n",
      "File \u001B[1;32mC:\\Program Files\\Python311\\Lib\\site-packages\\sklearn\\base.py:626\u001B[0m, in \u001B[0;36mBaseEstimator._validate_data\u001B[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001B[0m\n\u001B[0;32m    623\u001B[0m     out \u001B[38;5;241m=\u001B[39m X, y\n\u001B[0;32m    625\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m check_params\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mensure_2d\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[1;32m--> 626\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_check_n_features\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreset\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    628\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m out\n",
      "File \u001B[1;32mC:\\Program Files\\Python311\\Lib\\site-packages\\sklearn\\base.py:415\u001B[0m, in \u001B[0;36mBaseEstimator._check_n_features\u001B[1;34m(self, X, reset)\u001B[0m\n\u001B[0;32m    412\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[0;32m    414\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m n_features \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_features_in_:\n\u001B[1;32m--> 415\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    416\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX has \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mn_features\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m features, but \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    417\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mis expecting \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_features_in_\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m features as input.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    418\u001B[0m     )\n",
      "\u001B[1;31mValueError\u001B[0m: X has 10 features, but LinearRegression is expecting 2 features as input."
     ]
    }
   ],
   "source": [
    "# Initialize a dictionary to store the models for each charge\n",
    "models = {}\n",
    "\n",
    "# Loop over each charge\n",
    "for charge in range(1, 5):\n",
    "    # Filter the data for the current charge\n",
    "    mb_charge_frame = mb_clean_frame[mb_clean_frame['Charge'] == charge]\n",
    "    # Split the data into input and output variables\n",
    "    X_charge = mb_charge_frame[['Mass', 'Length']]\n",
    "    y_charge = mb_charge_frame['CCS_z']\n",
    "\n",
    "    # Initialize the cross-validation object\n",
    "    kf = KFold(n_splits=k)\n",
    "\n",
    "    # Initialize lists to store the scores for each fold\n",
    "    mse_scores_charge = []\n",
    "    median_relative_errors_charge = []\n",
    "    r2_scores_charge = []\n",
    "    \n",
    "    # Perform k-fold cross-validation\n",
    "    for train_index, test_index in kf.split(X_charge):\n",
    "        # Split the data into training and testing sets for the current fold\n",
    "        X_train, X_test = X_charge.iloc[train_index], X_charge.iloc[test_index]\n",
    "        y_train, y_test = y_charge.iloc[train_index], y_charge.iloc[test_index]\n",
    "\n",
    "        # Create a linear regression model\n",
    "        model = LinearRegression(n_jobs=-1)\n",
    "        \n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions on the test set\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Convert predictions back to original scale\n",
    "        y_pred_orig = y_pred * ccs_std + ccs_mean\n",
    "        y_test_orig = y_test * ccs_std + ccs_mean\n",
    "    \n",
    "        # Calculate the scores for the current fold\n",
    "        mse_scores_charge.append(mean_squared_error(y_test_orig, y_pred_orig))\n",
    "        median_relative_errors_charge.append(np.median(np.abs((y_pred_orig - y_test_orig) / y_test_orig)))\n",
    "        r2_scores_charge.append(r2_score(y_test_orig, y_pred_orig))\n",
    "\n",
    "    # Create the final model for the current charge\n",
    "    final_model_charge = LinearRegression(n_jobs=-1)\n",
    "    final_model_charge.fit(X_charge, y_charge)\n",
    "    \n",
    "    # Store the final model in the dictionary\n",
    "    models[charge] = final_model_charge\n",
    "    \n",
    "    # Print the scores for the current charge\n",
    "    print(f'Charge: {charge}')\n",
    "    print(f'Average Mean Squared Error: {np.mean(mse_scores_charge)}')\n",
    "    print(f'Average Median Relative Error: {np.mean(median_relative_errors_charge)}')\n",
    "    print(f'Average R^2 Score: {np.mean(r2_scores_charge)}')\n",
    "\n",
    "# Now, 'models' is a dictionary that maps each charge to its corresponding model.\n",
    "# You can access a model like this: models[charge]\n"
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create a new figure\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Define the colormap\n",
    "cmap = plt.get_cmap('winter')\n",
    "\n",
    "# Loop over each charge\n",
    "for charge in range(1, 5):\n",
    "    # Filter the data for the current charge\n",
    "    mb_charge_frame = mb_clean_frame[mb_clean_frame['Charge'] == charge]\n",
    "    \n",
    "    # Predict the CCS values using the model for the current charge\n",
    "    mb_charge_frame['Predicted CCS'] = models[charge].predict(mb_charge_frame[['Mass', 'Length']])\n",
    "    \n",
    "    # Reverse the z-score transformation\n",
    "    mb_charge_frame['Predicted CCS'] = mb_charge_frame['Predicted CCS'] * ccs_std + ccs_mean\n",
    "    \n",
    "    # Create a scatter plot of the error between the predicted and actual CCS values by sequence length\n",
    "    sc = ax.scatter(\n",
    "        mb_charge_frame['CCS'],\n",
    "        mb_charge_frame['Predicted CCS'],\n",
    "        c=mb_charge_frame['Length'],\n",
    "        cmap=cmap,\n",
    "        alpha=0.2,\n",
    "        vmin=mb_charge_frame['Length'].min(),\n",
    "        vmax=mb_charge_frame['Length'].max()\n",
    "    )\n",
    "\n",
    "# Add a colorbar to the figure\n",
    "fig.colorbar(sc, ax=ax, label='Sequence Length')\n",
    "\n",
    "# Add labels to the axes\n",
    "ax.set_xlabel('CCS')\n",
    "ax.set_ylabel('Predicted CCS')\n",
    "\n",
    "# Show the figure\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-09T11:56:44.952061Z",
     "start_time": "2023-10-09T11:56:40.467681Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for key in models:\n",
    "    mb_charge_frame = mb_clean_frame[mb_clean_frame['Charge'] == key]\n",
    "\n",
    "    # Predict the CCS of the peptides in the data frame\n",
    "    mb_charge_frame['Predicted CCS'] = models[key].predict(mb_charge_frame[['Mass', 'Length']])\n",
    "\n",
    "    # Reverse the z-score transformation\n",
    "    mb_charge_frame['Predicted CCS'] = mb_charge_frame['Predicted CCS'] * ccs_std + ccs_mean\n",
    "\n",
    "    ccs_data = mb_charge_frame[\"CCS\"].to_numpy()\n",
    "    predicted_ccs_data = mb_charge_frame[\"Predicted CCS\"].to_numpy()\n",
    "\n",
    "    x = mb_charge_frame[\"CCS\"]\n",
    "    y = mb_charge_frame[\"Predicted CCS\"]\n",
    "\n",
    "    plt_min = [mb_charge_frame[\"CCS\"].min(), mb_charge_frame[\"Predicted CCS\"].min()]\n",
    "    plt_max = [mb_charge_frame[\"CCS\"].max(), mb_charge_frame[\"Predicted CCS\"].max()]\n",
    "\n",
    "    range_min = 0\n",
    "    range_max = 0\n",
    "\n",
    "    if plt_min[0] < plt_min[1]:\n",
    "        range_min = plt_min[0]\n",
    "    else:\n",
    "        range_min = plt_min[1]\n",
    "\n",
    "    if plt_max[0] > plt_max[1]:\n",
    "        range_max = plt_max[0]\n",
    "    else:\n",
    "        range_max = plt_max[1]\n",
    "\n",
    "    if key == 100:\n",
    "        plt.hist2d(x, y, bins=[30,30], norm=colors.LogNorm(), range=((0, 1.4*1e-35), (0, 1.4*1e-35)))\n",
    "    else:\n",
    "        plt.hist2d(x, y, bins=[30,30], norm=colors.LogNorm(), range=((range_min, range_max), (range_min, range_max)))\n",
    "    plt.colorbar()\n",
    "    plt.title(f\"Charge {key}\")\n",
    "    plt.xlabel(\"Experimental CCS\")\n",
    "    plt.ylabel(\"Predicted CCS\")\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for key in models:\n",
    "    mb_charge_frame = mb_clean_frame[mb_clean_frame['Charge'] == key]\n",
    "    # Predict the CCS of the peptides in the data frame\n",
    "    mb_charge_frame['Predicted CCS'] = models[key].predict(mb_charge_frame[['Mass', 'Length']])\n",
    "\n",
    "    # Reverse the z-score transformation\n",
    "    mb_charge_frame['Predicted CCS'] = mb_charge_frame['Predicted CCS'] * ccs_std + ccs_mean\n",
    "\n",
    "    ccs_data = mb_charge_frame[\"CCS\"].to_numpy()\n",
    "    predicted_ccs_data = mb_charge_frame[\"Predicted CCS\"].to_numpy()\n",
    "\n",
    "    x = mb_charge_frame[\"CCS\"]\n",
    "    y = mb_charge_frame[\"Predicted CCS\"]\n",
    "\n",
    "    plt.hist2d(x, y, bins=[30,30], norm=colors.LogNorm(), range=((0.5*1e-35, 5*1e-35), (3*1e-36, 4.3*1e-35)))\n",
    "    plt.colorbar()\n",
    "    plt.title(f\"Charge {key}\")\n",
    "    plt.xlabel(\"Experimental CCS\")\n",
    "    plt.ylabel(\"Predicted CCS\")\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "for key in models:\n",
    "    mb_charge_frame = mb_clean_frame[mb_clean_frame['Charge'] == key]\n",
    "    # Predict the CCS of the peptides in the data frame\n",
    "    mb_charge_frame['Predicted CCS'] = models[key].predict(mb_charge_frame[['Mass', 'Length']])\n",
    "\n",
    "    # Reverse the z-score transformation\n",
    "    mb_charge_frame['Predicted CCS'] = mb_charge_frame['Predicted CCS'] * ccs_std + ccs_mean\n",
    "\n",
    "    ccs_data = mb_charge_frame[\"CCS\"].to_numpy()\n",
    "    predicted_ccs_data = mb_charge_frame[\"Predicted CCS\"].to_numpy()\n",
    "\n",
    "    x += mb_charge_frame[\"CCS\"].tolist()\n",
    "    y += mb_charge_frame[\"Predicted CCS\"].tolist()\n",
    "\n",
    "\n",
    "plt.hist2d(x, y, bins=[30,30], norm=colors.LogNorm(), range=((3*1e-36, 4.7*1e-35), (3*1e-36, 4.7*1e-35)))\n",
    "plt.colorbar()\n",
    "plt.title(\"All Charges\")\n",
    "plt.xlabel(\"Experimental CCS\")\n",
    "plt.ylabel(\"Predicted CCS\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(models)\n",
    "for key in models:\n",
    "    importance = models[key].coef_\n",
    "    # summarize feature importance\n",
    "    for i,v in enumerate(importance):\n",
    "     print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "\n",
    "    # plot feature importance\n",
    "    plt.bar([x for x in range(len(importance))], importance, color=\"#3070B3\")\n",
    "    plt.title(\"Feature Importance Charge \" + str(key))\n",
    "    features = X.columns\n",
    "    plt.xticks(range(X.shape[1]), models[key].feature_names_in_, rotation=0)\n",
    "    plt.xlim([-1, X.shape[1]])\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Save the model to a file"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#filename = '../../models/lin_reg/lin_reg.pkl'\n",
    "#pickle.dump(model, open(filename, 'wb'))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
